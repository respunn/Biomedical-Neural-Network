{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3116d5a7eb221",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T18:01:52.921326200Z",
     "start_time": "2023-10-26T18:01:49.550112500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba9df916745e41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T18:01:54.468742400Z",
     "start_time": "2023-10-26T18:01:52.987443400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "target_size = (256, 256)\n",
    "folder_name = \"testcovid\"\n",
    "directory = f\"../Datasets/{folder_name}/Splitted_Dataset\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=50,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "# validation_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=f\"{directory}/train\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    target_size=target_size,\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=f\"{directory}/test\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=target_size,\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    # directory=f\"{directory}/val\",\n",
    "    directory=f\"{directory}/train\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=target_size,\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DenseNetBase = DenseNet121(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "layer = DenseNetBase.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "\n",
    "layer = Dense(1024, activation='relu', kernel_initializer='he_normal')(layer)\n",
    "\n",
    "DenseNetPreds = Dense(2, activation='softmax')(layer)\n",
    "\n",
    "DenseNetModel = Model(inputs=DenseNetBase.input, outputs=DenseNetPreds)\n",
    "\n",
    "print(f\"Toplam DenseNet katman sayısı: {len(DenseNetModel.layers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in DenseNetBase.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in DenseNetBase.layers[-100:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "DenseNetModel.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "DenseNetModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DenseNetEpochs = 50\n",
    "\n",
    "DenseNetHistory = DenseNetModel.fit(\n",
    "    x=train_generator, validation_data=validation_generator, epochs=DenseNetEpochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ea515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode=\"max\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "DenseNetHistory2 = DenseNetModel.fit(\n",
    "    x=train_generator, validation_data=validation_generator, epochs=10, callbacks=[early_stopping]\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DenseNetModel.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNetBase = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "layer2 = ResNetBase.output\n",
    "\n",
    "layer2 = GlobalAveragePooling2D()(layer2)\n",
    "\n",
    "layer2 = Dense(1024, activation='relu')(layer2)\n",
    "\n",
    "ResNetPreds = Dense(2, activation='softmax')(layer2)\n",
    "\n",
    "ResNetModel = Model(inputs=ResNetBase.input, outputs=ResNetPreds)\n",
    "\n",
    "print(f\"Toplam ResNet katman sayısı: {len(ResNetModel.layers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in ResNetBase.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in ResNetBase.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "ResNetModel.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ResNetModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNetEpochs = 50\n",
    "\n",
    "ResNetHistory = ResNetModel.fit(\n",
    "    x=train_generator, validation_data=validation_generator, epochs=ResNetEpochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNetModel.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78da37",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "XceptionBase = Xception(weights='imagenet', include_top=False, input_shape=(256,256,3))\n",
    "\n",
    "layer3 = XceptionBase.output\n",
    "layer3 = GlobalAveragePooling2D()(layer3)\n",
    "\n",
    "layer3 = Dense(128, activation='relu')(layer3)\n",
    "\n",
    "XceptionPreds = Dense(2, activation='softmax')(layer3)\n",
    "\n",
    "XceptionModel = Model(inputs=XceptionBase.input, outputs=XceptionPreds)\n",
    "\n",
    "print(f\"Xception katman sayısı: {len(XceptionModel.layers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e02549",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in XceptionBase.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in XceptionBase.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "XceptionModel.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "XceptionModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa99a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "XceptionEpochs = 50\n",
    "\n",
    "XceptionHistory = XceptionModel.fit(\n",
    "    x=train_generator, validation_data=validation_generator, epochs=XceptionEpochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd1a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "XceptionModel.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e17655",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16Base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "layer4 = VGG16Base.output\n",
    "layer4 = GlobalAveragePooling2D()(layer4)\n",
    "layer4 = Dense(1024, activation='relu')(layer4)\n",
    "VGG16Preds = Dense(2, activation='softmax')(layer4)\n",
    "\n",
    "VGG16Model = Model(inputs=VGG16Base.input, outputs=VGG16Preds)\n",
    "print(f\"Toplam ResNet katman sayısı: {len(VGG16Model.layers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136dea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in VGG16Base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in VGG16Base.layers[-7:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "VGG16Model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "VGG16Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ba610",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16Epochs = 50\n",
    "\n",
    "VGG16History = VGG16Model.fit(\n",
    "    x=train_generator, validation_data=validation_generator, epochs=VGG16Epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8727e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16Model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb9042",
   "metadata": {},
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "InceptionBase = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "layer5 = InceptionBase.output\n",
    "layer5 = GlobalAveragePooling2D()(layer5)\n",
    "layer5 = Dense(1024, activation='relu')(layer5)\n",
    "InceptionPreds = Dense(2, activation='softmax')(layer5)\n",
    "\n",
    "InceptionModel = Model(inputs=InceptionBase.input, outputs=InceptionPreds)\n",
    "print(f\"Toplam ResNet katman sayısı: {len(InceptionModel.layers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239818cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in InceptionBase.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in InceptionBase.layers[-100:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "InceptionModel.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "InceptionModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a932841",
   "metadata": {},
   "outputs": [],
   "source": [
    "InceptionEpochs = 50\n",
    "\n",
    "InceptionHistory = InceptionModel.fit(\n",
    "    x=train_generator, validation_data=validation_generator, epochs=InceptionEpochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efcf626",
   "metadata": {},
   "outputs": [],
   "source": [
    "InceptionModel.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b5e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 2, figsize=(20, 30))\n",
    "\n",
    "axs[0, 0].set_title(\"DenseNet\")\n",
    "axs[0, 1].set_title(\"DenseNet\")\n",
    "axs[1, 0].set_title(\"ResNet\")\n",
    "axs[1, 1].set_title(\"ResNet\")\n",
    "axs[2, 0].set_title(\"Xception\")\n",
    "axs[2, 1].set_title(\"Xception\")\n",
    "axs[3, 0].set_title(\"VGG16\")\n",
    "axs[3, 1].set_title(\"VGG16\")\n",
    "axs[4, 0].set_title(\"Inception\")\n",
    "axs[4, 1].set_title(\"Inception\")\n",
    "\n",
    "axs[0, 0].set_xlabel(\"Epoch\")\n",
    "axs[0, 1].set_xlabel(\"Epoch\")\n",
    "axs[1, 0].set_xlabel(\"Epoch\")\n",
    "axs[1, 1].set_xlabel(\"Epoch\")\n",
    "axs[2, 0].set_xlabel(\"Epoch\")\n",
    "axs[2, 1].set_xlabel(\"Epoch\")\n",
    "axs[3, 0].set_xlabel(\"Epoch\")\n",
    "axs[3, 1].set_xlabel(\"Epoch\")\n",
    "axs[4, 0].set_xlabel(\"Epoch\")\n",
    "axs[4, 1].set_xlabel(\"Epoch\")\n",
    "\n",
    "axs[0, 0].plot(DenseNetHistory.history['accuracy'], label='DenseNet Training Accuracy')\n",
    "axs[0, 0].set_title('Training Accuracy')\n",
    "axs[0, 0].legend()\n",
    "axs[0, 0].plot(DenseNetHistory.history['val_accuracy'], label='DenseNet Validation Accuracy')\n",
    "axs[0, 0].set_title('Validation Accuracy')\n",
    "axs[0, 0].legend()\n",
    "\n",
    "axs[0, 1].plot(DenseNetHistory.history['loss'], label='DenseNet Training Loss')\n",
    "axs[0, 1].set_title('Training Loss')\n",
    "axs[0, 1].legend()\n",
    "axs[0, 1].plot(DenseNetHistory.history['val_loss'], label='DenseNet Validation Loss')\n",
    "axs[0, 1].set_title('Validation Loss')\n",
    "axs[0, 1].legend()\n",
    "\n",
    "axs[1, 0].plot(ResNetHistory.history['accuracy'], label='ResNet Training Accuracy')\n",
    "axs[1, 0].set_title('Training Accuracy')\n",
    "axs[1, 0].legend()\n",
    "axs[1, 0].plot(ResNetHistory.history['val_accuracy'], label='ResNet Validation Accuracy')\n",
    "axs[1, 0].set_title('Validation Accuracy')\n",
    "axs[1, 0].legend()\n",
    "\n",
    "axs[1, 1].plot(ResNetHistory.history['loss'], label='ResNet Training Loss')\n",
    "axs[1, 1].set_title('Training Loss')\n",
    "axs[1, 1].legend()\n",
    "axs[1, 1].plot(ResNetHistory.history['val_loss'], label='ResNet Validation Loss')\n",
    "axs[1, 1].set_title('Validation Loss')\n",
    "axs[1, 1].legend()\n",
    "\n",
    "axs[2, 0].plot(XceptionHistory.history['accuracy'], label='Xception Training Accuracy')\n",
    "axs[2, 0].set_title('Training Accuracy')\n",
    "axs[2, 0].legend()\n",
    "axs[2, 0].plot(XceptionHistory.history['val_accuracy'], label='Xception Validation Accuracy')\n",
    "axs[2, 0].set_title('Validation Accuracy')\n",
    "axs[2, 0].legend()\n",
    "\n",
    "axs[2, 1].plot(XceptionHistory.history['loss'], label='Xception Training Loss')\n",
    "axs[2, 1].set_title('Training Loss')\n",
    "axs[2, 1].legend()\n",
    "axs[2, 1].plot(XceptionHistory.history['val_loss'], label='Xception Validation Loss')\n",
    "axs[2, 1].set_title('Validation Loss')\n",
    "axs[2, 1].legend()\n",
    "\n",
    "axs[3, 0].plot(VGG16History.history['accuracy'], label='VGG16 Training Accuracy')\n",
    "axs[3, 0].set_title('Training Accuracy')\n",
    "axs[3, 0].legend()\n",
    "axs[3, 0].plot(VGG16History.history['val_accuracy'], label='VGG16 Validation Accuracy')\n",
    "axs[3, 0].set_title('Validation Accuracy')\n",
    "axs[3, 0].legend()\n",
    "\n",
    "axs[3, 1].plot(VGG16History.history['loss'], label='VGG16 Training Loss')\n",
    "axs[3, 1].set_title('Training Loss')\n",
    "axs[3, 1].legend()\n",
    "axs[3, 1].plot(VGG16History.history['val_loss'], label='VGG16 Validation Loss')\n",
    "axs[3, 1].set_title('Validation Loss')\n",
    "axs[3, 1].legend()\n",
    "\n",
    "axs[4, 0].plot(InceptionHistory.history['accuracy'], label='Inception Training Accuracy')\n",
    "axs[4, 0].set_title('Training Accuracy')\n",
    "axs[4, 0].legend()\n",
    "axs[4, 0].plot(InceptionHistory.history['val_accuracy'], label='Inception Validation Accuracy')\n",
    "axs[4, 0].set_title('Validation Accuracy')\n",
    "axs[4, 0].legend()\n",
    "\n",
    "axs[4, 1].plot(InceptionHistory.history['loss'], label='Inception Training Loss')\n",
    "axs[4, 1].set_title('Training Loss')\n",
    "axs[4, 1].legend()\n",
    "axs[4, 1].plot(InceptionHistory.history['val_loss'], label='Inception Validation Loss')\n",
    "axs[4, 1].set_title('Validation Loss')\n",
    "axs[4, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# plt.suptitle(\"DenseNet - 100 Katman, ResNet - 10 Katman, Xception - 35 Katman Açık, AdaDelta Optimizer, Özel Epoch\")\n",
    "\n",
    "axs[0, 0].plot(DenseNetHistory.history['accuracy'], label='DenseNet Training Accuracy')\n",
    "axs[0, 0].set_title('Training Accuracy')\n",
    "axs[0, 0].legend()\n",
    "axs[0, 0].plot(DenseNetHistory.history['val_accuracy'], label='DenseNet Validation Accuracy')\n",
    "axs[0, 0].set_title('Validation Accuracy')\n",
    "axs[0, 0].legend()\n",
    "\n",
    "axs[0, 1].plot(DenseNetHistory.history['loss'], label='DenseNet Training Loss')\n",
    "axs[0, 1].set_title('Training Loss')\n",
    "axs[0, 1].legend()\n",
    "axs[0, 1].plot(DenseNetHistory.history['val_loss'], label='DenseNet Validation Loss')\n",
    "axs[0, 1].set_title('Validation Loss')\n",
    "axs[0, 1].legend()\n",
    "\n",
    "axs[1, 0].plot(XceptionHistory.history['accuracy'], label='ResNet Training Accuracy')\n",
    "axs[1, 0].set_title('Training Accuracy')\n",
    "axs[1, 0].legend()\n",
    "axs[1, 0].plot(XceptionHistory.history['val_accuracy'], label='ResNet Validation Accuracy')\n",
    "axs[1, 0].set_title('Validation Accuracy')\n",
    "axs[1, 0].legend()\n",
    "\n",
    "axs[1, 1].plot(XceptionHistory.history['loss'], label='ResNet Training Loss')\n",
    "axs[1, 1].set_title('Training Loss')\n",
    "axs[1, 1].legend()\n",
    "axs[1, 1].plot(XceptionHistory.history['val_loss'], label='ResNet Validation Loss')\n",
    "axs[1, 1].set_title('Validation Loss')\n",
    "axs[1, 1].legend()\n",
    "\n",
    "axs[2, 0].plot(InceptionHistory.history['accuracy'], label='ResNet Training Accuracy')\n",
    "axs[2, 0].set_title('Training Accuracy')\n",
    "axs[2, 0].legend()\n",
    "axs[2, 0].plot(InceptionHistory.history['val_accuracy'], label='ResNet Validation Accuracy')\n",
    "axs[2, 0].set_title('Validation Accuracy')\n",
    "axs[2, 0].legend()\n",
    "\n",
    "axs[2, 1].plot(InceptionHistory.history['loss'], label='ResNet Training Loss')\n",
    "axs[2, 1].set_title('Training Loss')\n",
    "axs[2, 1].legend()\n",
    "axs[2, 1].plot(InceptionHistory.history['val_loss'], label='ResNet Validation Loss')\n",
    "axs[2, 1].set_title('Validation Loss')\n",
    "axs[2, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ee5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from nbconvert import HTMLExporter\n",
    "\n",
    "folder_path = f\"..\\\\Results\\\\{folder_name}\"\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "current_time = datetime.now().strftime(\"%H.%M_%d.%m.%Y\")\n",
    "\n",
    "html_filename = f\"{current_time}.html\"\n",
    "html_file_path = os.path.join(folder_path, html_filename)\n",
    "\n",
    "notebook_filename = \"main_project.ipynb\"\n",
    "exporter = HTMLExporter()\n",
    "output, _ = exporter.from_filename(notebook_filename)\n",
    "\n",
    "with open(html_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(output)\n",
    "\n",
    "print(f\"Notebook saved to {folder_path} as {html_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
